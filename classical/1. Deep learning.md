# Deep learning
> Author: Yann LeCun, Yoshua Bengio & Geoffrey Hinton  
> Journal: Nature  
> Year: 2015  
> [Source paper link](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)



# Abstract
Two key sentences:
1. Deep learning allows computational models that are composed of **multiple processing layers** to **learn representations of data** with multiple levels of abstraction.
2. Deep learning discovers intricate structure in large data sets by using the **backpropagation algorithm** to indicate how a machine should **change its internal parameters** that are used to compute the representation in each layer from the representation in the previous layer.

# Introduction
## Why deep learning?
For decades, conventional machine-learning techniques were limited in their ability to process natural data in their raw form. While deep learning models are **end-to-end**, which means it's able to find the intricate structures in data **without the help of human engineers**.

## What is deep learning?
Deep-learning methods are **representation-learning** methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level.

# Supervised learning
## The learning progress of supervised learning
1. **Forward propagation.** During training, the machine is shown an image and produces an output in the form of a vector of scores, one for each category.
2. **Compute the error.** Compute an objective function that measures the error (or distance) between the output scores and the desired pattern of scores. 
3. **Back propagation.** The machine then modifies its internal adjustable parameters (called 'weights') to reduce this error.

## The shallow classifier's incapabilities
For **shallow classifiers**, there exists the **selectivityâ€“invariance
dilemma** -- one that produces representations that are selective to
the aspects of the image that are important for discrimination, but
that are invariant to irrelevant aspects such as the pose of the animal.  
Though more powerful classifiers can be built using **generic non-linear features**, as with kernel methods, it still possess the problem of **bad generalization**.  
> That's where deep learning methods come in!

# Backpropagation to train multilayer architectures
## The mechanism of backpropagation
> Quote: The backpropagation procedure to compute the gradient of an objective function with respect to the weights of a multilayer stack of modules is nothing more than a practical application of the chain rule for derivatives.

![image](./img/1_1.png)

> Figure b. Chain rules for derivatives  
> Figure c. Forward propagation  
> Figure d. Backpropagation

## Why a 1980s method gets its revival after 2006?
- CIFAR's innovative methods to get sensible initialized weights so that BP could become feasible for deep system.
- The advent of fast graphics processing units (GPUs)

# Convolutional neural networks
> Born in 1990s.  
> Four key ideas behind ConvNets: **local connections**, **shared weights**, **pooling** and **the use of many layers**.  

![image](./img/1_2.png)

## Parameter sharing rules for convolutional layers
**Rules**
- All units in a feature map share the same filter bank.
- Different feature maps in a layer use different filter banks.
  
**Ideas behind the rules**
- In array data such as images, local groups of values are often highly correlated, forming distinctive local motifs that are easily detected.
- The local statistics of images and other signals are invariant to location.

## The function of Pooling layers
The role of the pooling layer is to **merge semantically similar features into one**, creating an **invariance** to small shifts and distortions.

# Image understanding with deep convolutional networks
> The application of ConvNets.

# Distributed representations and language processing
